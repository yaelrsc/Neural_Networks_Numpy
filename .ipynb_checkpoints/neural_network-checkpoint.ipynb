{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d39416d-6474-42a0-98ea-d7f2561495ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import numpy as np\n",
    "from autograd.scipy.stats import  norm , t\n",
    "from autograd import deriv,elementwise_grad,grad,jacobian,holomorphic_grad\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de491cf-50ad-42fd-9842-5029b10fe048",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Activation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5caf04-4e86-431c-8792-f37ac5827a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation():\n",
    "    \n",
    "    def __init__(self,name,**kwargs):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        for kw in kwargs:\n",
    "            \n",
    "            exec('self.{} = {} '.format(kw, kwargs[kw]))\n",
    "        \n",
    "    def __call_(self,x):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def derivative(self,x):\n",
    "        \n",
    "        return deriv(self)(x)\n",
    "\n",
    "\n",
    "class Linear(Activation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='linear')\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class GeneralizedSigmoid(Activation):\n",
    "    \n",
    "    def __init__(self,C=1.0):\n",
    "        \n",
    "        super().__init__(name='generalized_sigmoid',C=C)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        \n",
    "        return self.C/(self.C + np.exp(-x))\n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='sigmoid')\n",
    "        \n",
    "        \n",
    "    def __call__(self,x):\n",
    "        \n",
    "        return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "class Tanh(Activation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='tanh')\n",
    "        \n",
    "        \n",
    "    def __call__(self,x):\n",
    "        \n",
    "        return np.tanh(x)\n",
    "\n",
    "class Relu(Activation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__('relu')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        return np.where(x>0,x,0)\n",
    "\n",
    "class Elu(Activation):\n",
    "    \n",
    "    def __init__(self,alpha = 1.0):\n",
    "        \n",
    "        super().__init__('elu',alpha=alpha)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        return np.where(x>=0,x,self.alpha*(np.exp(x)-1))\n",
    "\n",
    "class Softmax(Activation):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__('softmax')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "\n",
    "        ex = np.exp(x)\n",
    "    \n",
    "        return ex/(ex.sum(axis=1).reshape(-1,1))\n",
    "    \n",
    "    def derivative(self,x):\n",
    "        \n",
    "        return self(x)*(1-self(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265a97b-30bd-45ca-bb8d-0bf10cee4f01",
   "metadata": {},
   "source": [
    "# Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16baa12e-5466-417a-aadc-61bb57a741f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss():\n",
    "    \n",
    "    def __init__(self,name,**kwargs):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        for kw in kwargs:\n",
    "            \n",
    "            exec('self.{} = {} '.format(kw, kwargs[kw]))\n",
    "        \n",
    "    def __call_(self,y_true,y_pred):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def derivative(self,y_true,y_pred):\n",
    "        \n",
    "        return elementwise_grad(self,1)(y_true,y_pred)\n",
    "\n",
    "class MeanSquaredError(Loss):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super().__init__('mean_squared_error')\n",
    "    \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        e2 = (y_true-y_pred)**2\n",
    "\n",
    "        return (1/2)*np.mean(e2)\n",
    "\n",
    "class MeanAbsoluteError(Loss):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super().__init__('mean_absolute_error')\n",
    "    \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        ae = np.abs(y_true-y_pred)\n",
    "\n",
    "        return np.mean(ae)\n",
    "\n",
    "class MeanSquaredLogarithmicError(Loss):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super().__init__('mean_squared_logarithmic_error')\n",
    "    \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        le2 = (np.log(y_true)-np.log(y_pred))**2\n",
    "\n",
    "        return (1/2)*np.mean(le2)\n",
    "\n",
    "\n",
    "class Huber_Loss(Loss):\n",
    "    \n",
    "    def __init__(self,delta=1.0):\n",
    "\n",
    "        super().__init__('huber_loss',delta=delta)\n",
    "  \n",
    "    def __call__(self,y_true,y_pred):\n",
    "\n",
    "        delta = self.delta\n",
    "\n",
    "        ae = np.abs(y_true-y_pred)\n",
    "\n",
    "        e2 = (y_true-y_pred)**2\n",
    "\n",
    "        hloss = np.where(ae<=delta, (1/2)*e2, delta*ae-(1/2)*(delta**2))\n",
    "\n",
    "        return np.mean(hloss)\n",
    "\n",
    "class BinaryCrossEntropy(Loss):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__('binary_cross_entropy')\n",
    "  \n",
    "    def __call__(self, y_true, y_pred):\n",
    "    \n",
    "        return -np.mean(y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))\n",
    "\n",
    "class Categorical_Cross_Entropy(Loss):\n",
    "  \n",
    "    def __init__(self):\n",
    "    \n",
    "        super().__init__('categorical_cross_entropy')\n",
    "  \n",
    "    def __call__(self, y_true, y_pred):\n",
    "    \n",
    "        return -np.mean(y_true*np.log(y_pred),axis=0)\n",
    "  \n",
    "    def derivative(self, y_true, y_pred):\n",
    "        \n",
    "        return super().derivative(y_true, y_pred)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb7b60-5bbb-4c1b-835c-86c521346e6e",
   "metadata": {},
   "source": [
    "# Metric Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd375465-6346-48a3-8c4c-43c6691feaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    \n",
    "    def __init__(self,name,**kwargs):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        for kw in kwargs:\n",
    "            \n",
    "            exec('self.{} = {} '.format(kw, kwargs[kw]))\n",
    "    \n",
    "    def __call_(self,y_true,y_pred):\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "class BinaryAccuracy(Metric):\n",
    "    \n",
    "    def __init__(self,threshold=0.5):\n",
    "\n",
    "        super().__init__('binary_accuracy',threshold=threshold)\n",
    "  \n",
    "    def __call__(self,y_true,y_pred):\n",
    "\n",
    "        y_true = y_true.astype(float).reshape(-1,1)\n",
    "\n",
    "        y_pred = np.where(y_pred>self.threshold,1.,0.).reshape(-1,1)\n",
    "\n",
    "        return len(y_true[y_true == y_pred])/len(y_true)\n",
    "\n",
    "\n",
    "\n",
    "class Precision(Metric):\n",
    "    \n",
    "    def __init__(self,threshold=0.5):\n",
    "        \n",
    "        super().__init__('precision',threshold=threshold)\n",
    "        \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        y_true = y_true.astype(float).reshape(-1,1)\n",
    "        \n",
    "        y_pred = np.where(y_pred>self.threshold,1.,0.).reshape(-1,1)\n",
    "    \n",
    "        P = (y_true == 1.)\n",
    "        \n",
    "        TP = len(y_true[P][y_true[P] == y_pred[P]])\n",
    "        FP = len(y_true[P][y_true[P] != y_pred[P]])\n",
    "        \n",
    "        return TP/(TP + FP)\n",
    "\n",
    "class Recall(Metric):\n",
    "    \n",
    "    def __init__(self,threshold=0.5):\n",
    "        \n",
    "        super().__init__('recall',threshold=threshold)\n",
    "        \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        y_true = y_true.astype(float).reshape(-1,1)\n",
    "        \n",
    "        y_pred = np.where(y_pred>self.threshold,1.,0.).reshape(-1,1)\n",
    "        \n",
    "        P = (y_true==1.)\n",
    "        N = (y_true==0.)\n",
    "        \n",
    "        TP = len(y_true[P][y_true[P] == y_pred[P]])\n",
    "        FN = len(y_true[N][y_true[N] != y_pred[N]])\n",
    "        \n",
    "        return TP/(TP + FN)\n",
    "\n",
    "class FPRate(Metric):\n",
    "    \n",
    "    def __init__(self,threshold=0.5):\n",
    "        \n",
    "        super().__init__('fp_rate',threshold=threshold)\n",
    "        \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        y_true = y_true.astype(float).reshape(-1,1)\n",
    "        \n",
    "        y_pred = np.where(y_pred>self.threshold,1.,0.).reshape(-1,1)\n",
    "    \n",
    "        P = (y_true==1.)\n",
    "        N = (y_true==0.)\n",
    "        \n",
    "        FP = len(y_true[P][y_true[P] != y_pred[P]])\n",
    "        \n",
    "        TN = len(y_true[N][y_true[N] == y_pred[N]])\n",
    "        \n",
    "        return FP/(TN + FP)\n",
    "\n",
    "class Specificity(Metric):\n",
    "    \n",
    "    def __init__(self,threshold=0.5):\n",
    "        \n",
    "        super().__init__('specificity',threshold=threshold)\n",
    "        \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        y_true = y_true.astype(float).reshape(-1,1)\n",
    "        \n",
    "        y_pred = np.where(y_pred>self.threshold,1.,0.).reshape(-1,1)\n",
    "    \n",
    "        P = (y_true==1.)\n",
    "        N = (y_true==0.)\n",
    "        \n",
    "        FP = len(y_true[P][y_true[P] != y_pred[P]])\n",
    "        TN = len(y_true[N][y_true[N] == y_pred[N]])\n",
    "        \n",
    "        return TN/(TN + FP)\n",
    "\n",
    "class F1(Metric):\n",
    "    \n",
    "    def __init__(self,threshold=0.5):\n",
    "        \n",
    "        super().__init__('f1',threshold=threshold)\n",
    "        \n",
    "    def __call__(self,y_true,y_pred):\n",
    "        \n",
    "        y_true = y_true.astype(float).reshape(-1,1)\n",
    "        \n",
    "        y_pred = np.where(y_pred>self.threshold,1.,0.).reshape(-1,1)\n",
    "    \n",
    "        P = (y_true==1.)\n",
    "        N = (y_true==0.)\n",
    "        \n",
    "        TP = len(y_true[P][y_true[P] == y_pred[P]])\n",
    "        FP = len(y_true[P][y_true[P] != y_pred[P]])\n",
    "        FN = len(y_true[N][y_true[N] != y_pred[N]])\n",
    "        \n",
    "        return 2*TP/(2*TP + FP+ FN)\n",
    "\n",
    "\n",
    "\n",
    "class R2_adjusted(Metric):\n",
    "    \n",
    "    def __init__(self,p):\n",
    "\n",
    "        super().__init__('r2_adjusted',p=p)\n",
    "  \n",
    "    def __call__(self,y_true,y_pred):\n",
    "\n",
    "        SSR = np.sum((y_pred-np.mean(y_true))**2)\n",
    "\n",
    "        SST = np.sum((y_true-np.mean(y_true))**2)\n",
    "        \n",
    "        R2 = 1-SSR/SST\n",
    "        N = len(y_true)\n",
    "        \n",
    "        return 1-(1-R2)*(N-1)/(N-p-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RSquared(Metric):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__('r_squared')\n",
    "  \n",
    "    def __call__(self,y_true,y_pred):\n",
    "\n",
    "        SSR = np.sum((y_pred-np.mean(y_true))**2)\n",
    "\n",
    "        SST = np.sum((y_true-np.mean(y_true))**2)\n",
    "\n",
    "        return SSR / SST\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b99873-e62b-46af-9efb-9cc6a59efcdf",
   "metadata": {},
   "source": [
    "# Initializer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad059f53-d356-4178-8038-ad139dd4f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initializer():\n",
    "    \n",
    "    def __init__(self,name,**kwargs):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        for kw in kwargs:\n",
    "            \n",
    "            exec('self.{} = {} '.format(kw, kwargs[kw]))\n",
    "    \n",
    "\n",
    "    def __call__(self, shape):\n",
    "        \n",
    "        pass\n",
    "\n",
    "class Normal(Initializer):\n",
    "    \n",
    "    def __init__(self,mu=0.0,sigma=1.0):\n",
    "        \n",
    "        super().__init__(name='normal',mu=mu,sigma=sigma)\n",
    "  \n",
    "    def __call__(self, shape):\n",
    "        \n",
    "        return np.random.normal(loc=self.mu,scale=self.sigma,size=shape)\n",
    "\n",
    "class Uniform(Initializer):\n",
    "    \n",
    "    def __init__(self,a=0.0,b=1.0):\n",
    "        \n",
    "        super().__init__(name='uniform',a=a,b=b)\n",
    "  \n",
    "    def __call__(self,shape):\n",
    "        \n",
    "        return np.random.uniform(low=self.a,high=self.b,size=shape)\n",
    "\n",
    "class Ones(Initializer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='ones')\n",
    "  \n",
    "    def __call__(self, shape):\n",
    "    \n",
    "        return np.ones(shape=shape)\n",
    "\n",
    "class Zeros(Initializer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='zeros')\n",
    "  \n",
    "    def __call__(self, shape):\n",
    "    \n",
    "        return np.zeros(shape=shape)\n",
    "    \n",
    "class GlorotNormal(Initializer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='glorot_normal')\n",
    "\n",
    "    def __call__(self, shape):\n",
    "\n",
    "        sigma = (2/(shape[1] + shape[0]))**(1/2)\n",
    "    \n",
    "        return np.random.normal(scale=sigma,size=shape)\n",
    "    \n",
    "class HeNormal(Initializer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(name='he_normal')\n",
    "\n",
    "    def __call__(self,shape):\n",
    "\n",
    "        sigma = (2/(shape[0]))**(1/2)\n",
    "    \n",
    "        return np.random.normal(scale=sigma,size=shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff0ac27-1b17-4ab0-a14c-c14460c03dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1.0,0.0,0.0,0.0,1.0,0.0,1.0])\n",
    "y_pred = np.array([0.85,0.29,0.6,0.01,0.9,0.8,0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f686ebad-9a70-4aec-a8a6-62e5a4c75b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = Specificity(threshold=0.5)\n",
    "\n",
    "1-metric(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "039ed039-f073-492f-ab32-fd26c4c83bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31352957, -0.22039007],\n",
       "       [-0.21898292, -1.132118  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = HeNormal()\n",
    "init((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4090f62d-a358-4b03-8390-b2b505ffdfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Returns a function which computes the Jacobian of `fun` with respect to\n",
       "positional argument number `argnum`, which must be a scalar or array. Unlike\n",
       "`grad` it is not restricted to scalar-output functions, but also it cannot\n",
       "take derivatives with respect to some argument types (like lists or dicts).\n",
       "If the input to `fun` has shape (in1, in2, ...) and the output has shape\n",
       "(out1, out2, ...) then the Jacobian has shape (out1, out2, ..., in1, in2, ...).\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\gaming\\anaconda3\\lib\\site-packages\\autograd\\wrap_util.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jacobian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653c5a7-7888-4dab-9f18-cb3bdd760ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
